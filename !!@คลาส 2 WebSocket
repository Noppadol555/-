# ===============================================
# websocket_manager.py  (Auto Fetch All USDT Pairs for Binance Futures â€¢ Safe Funding Rate â€¢ Historical Buffer â€¢ Dynamic Global Sync)
# ===============================================

import json
import asyncio
import time
import logging
import logging.handlers
import sqlite3
import websockets
import aiohttp
from datetime import timedelta
from collections import deque
from tenacity import retry, wait_exponential, stop_after_attempt
from config import GlobalConfig
import pandas as pd


# --------------------------- Logging ---------------------------
logging.basicConfig(
    level=getattr(logging, GlobalConfig.get("log_level", "INFO")),
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.handlers.RotatingFileHandler(
            "websocketmanager.log", maxBytes=10 * 1024 * 1024, backupCount=5
        ),
        logging.StreamHandler(),
    ],
)

FSTREAM_BASE = "wss://fstream.binance.com"
DSTREAM_BASE = "wss://dstream.binance.com"


class WebSocketManager:
    """WebSocket Manager à¸ªà¸³à¸«à¸£à¸±à¸š Binance Futures (à¸žà¸£à¹‰à¸­à¸¡ funding_rate à¸›à¸¥à¸­à¸”à¸ à¸±à¸¢ + Historical Buffer + Dynamic Global Sync)"""

    def __init__(self, exchange=None, time_offset: int = 0):
        self.exchange = exchange
        self.time_offset = time_offset

        # ðŸŸ¢ à¹‚à¸«à¸¥à¸”à¸„à¹ˆà¸²à¸ˆà¸²à¸ GlobalConfig à¸„à¸£à¸±à¹‰à¸‡à¹à¸£à¸
        self.refresh_config(initial=True)

        self.running = False
        self.subscribed_symbols = set()
        self.reconnect_attempts = 0
        self.data = {}
        self.cache = {}
        self.listen_key = None
        self.start_time = None
        self.last_data_time = time.time()
        self.all_usdt_pairs = []
        self.balance_data = {"free": 0.0, "locked": 0.0}
        self.price_buffer = {}

        # --------- SQLite ---------
        self.db_conn = sqlite3.connect(
            GlobalConfig.get("db_path", "ws_backup.db"),
            timeout=10,
            check_same_thread=False
        )
        self._init_db()

    # ---------------------- Dynamic Config Sync ----------------------
    def refresh_config(self, initial: bool = False):
        """ðŸŸ¢ à¸­à¸±à¸›à¹€à¸”à¸•à¸„à¹ˆà¸²à¸ˆà¸²à¸ GlobalConfig à¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™"""
        self.public_base = GlobalConfig.get("ws_url", FSTREAM_BASE)
        self.backup_base = GlobalConfig.get("ws_backup_url", DSTREAM_BASE)
        self.max_reconnects = int(GlobalConfig.get("max_reconnects", 10))
        self.reconnect_delay_max = int(GlobalConfig.get("reconnect_delay_max", 60))
        self.ws_timeout = int(GlobalConfig.get("ws_timeout", 10))
        self.db_path = GlobalConfig.get("db_path", "ws_backup.db")
        self.cache_size_max = int(GlobalConfig.get("cache_size_max", 1000))
        self.data_retention_limit = int(GlobalConfig.get("data_retention_limit", 100))
        self.multi_tf_list = list(GlobalConfig.get("multi_tf_list", []))
        self.historical_years = int(GlobalConfig.get("historical_years", 5))

        if not initial:
            logging.info("ðŸ”„ GlobalConfig à¸‚à¸­à¸‡ WebSocketManager à¸–à¸¹à¸à¸­à¸±à¸›à¹€à¸”à¸•à¹€à¸£à¸µà¸¢à¸šà¸£à¹‰à¸­à¸¢")

    async def auto_sync_config_loop(self, interval: int = 30):
        """à¸¥à¸¹à¸›à¸­à¸±à¸›à¹€à¸”à¸•à¸„à¹ˆà¸² config à¸ªà¸”à¸ˆà¸²à¸ GlobalConfig à¸—à¸¸à¸ à¹† X à¸§à¸´à¸™à¸²à¸—à¸µ"""
        while True:
            try:
                self.refresh_config()
            except Exception as e:
                logging.error(f"à¸­à¸±à¸›à¹€à¸”à¸• GlobalConfig à¹ƒà¸™ WebSocketManager à¸¥à¹‰à¸¡à¹€à¸«à¸¥à¸§: {e}")
            await asyncio.sleep(interval)

    # --------------------------- DB ---------------------------
    def _init_db(self):
        c = self.db_conn.cursor()
        c.execute(
            """CREATE TABLE IF NOT EXISTS ws_data (
                symbol TEXT,
                timestamp REAL,
                close REAL,
                volume REAL,
                funding_rate REAL,
                depth REAL
            )"""
        )
        self.db_conn.commit()

    async def _commit_safe(self):
        try:
            await asyncio.to_thread(self.db_conn.commit)
        except Exception as e:
            logging.error(f"Commit failed: {e}")

    # ---------------------- Fetch all USDT pairs ----------------------
    async def fetch_all_usdt_pairs(self):
        url = "https://fapi.binance.com/fapi/v1/exchangeInfo"
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=aiohttp.ClientTimeout(total=15)) as resp:
                    data = await resp.json()
                    symbols = [
                        s["symbol"]
                        for s in data.get("symbols", [])
                        if s.get("contractType") == "PERPETUAL" and s["symbol"].endswith("USDT")
                    ]
                    self.all_usdt_pairs = sorted(symbols)
                    logging.info(f"âœ… à¸”à¸¶à¸‡à¸„à¸¹à¹ˆà¹€à¸«à¸£à¸µà¸¢à¸ USDT à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸” {len(symbols)} à¸„à¸¹à¹ˆà¸ªà¸³à¹€à¸£à¹‡à¸ˆ")
        except Exception as e:
            logging.error(f"âŒ à¸”à¸¶à¸‡à¸„à¸¹à¹ˆà¹€à¸«à¸£à¸µà¸¢à¸ USDT à¸¥à¹‰à¸¡à¹€à¸«à¸¥à¸§: {e}")
            self.all_usdt_pairs = ["BTCUSDT", "ETHUSDT"]

    # ---------------------- Safe getter ----------------------
    def get_symbol_data(self, symbol: str) -> dict:
        d = self.data.get(symbol, {})
        return {
            "timestamp": d.get("timestamp", time.time()),
            "close": d.get("close", 0.0),
            "volume": d.get("volume", 0.0),
            "funding_rate": d.get("funding_rate", 0.0),
            "depth": d.get("depth", {}),
        }

    def get_latest_price(self, symbol: str) -> float:
        try:
            return float(self.data.get(symbol, {}).get("close", 0.0))
        except Exception:
            return 0.0

    def get_latest_balance(self) -> float:
        try:
            return float(self.balance_data.get("free", GlobalConfig.get("initial_balance", 100.0)))
        except Exception:
            return GlobalConfig.get("initial_balance", 100.0)

    # ---------------------- ListenKey ----------------------
    async def create_listen_key(self) -> str | None:
        try:
            api_key = GlobalConfig.get("binance_api_key")
            if not api_key:
                logging.warning("âš ï¸ à¹„à¸¡à¹ˆà¸¡à¸µ BINANCE API KEY à¹ƒà¸™ config; à¸‚à¹‰à¸²à¸¡ user stream")
                return None
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    "https://fapi.binance.com/fapi/v1/listenKey",
                    headers={"X-MBX-APIKEY": api_key},
                    timeout=aiohttp.ClientTimeout(total=10),
                ) as resp:
                    data = await resp.json()
                    self.listen_key = data.get("listenKey")
                    if self.listen_key:
                        logging.info(f"à¸ªà¸£à¹‰à¸²à¸‡ listenKey à¸ªà¸³à¹€à¸£à¹‡à¸ˆ: {self.listen_key[:10]}...")
                    return self.listen_key
        except Exception as e:
            logging.error(f"à¸ªà¸£à¹‰à¸²à¸‡ listenKey à¸¥à¹‰à¸¡à¹€à¸«à¸¥à¸§: {e}")
            return None

    async def keep_alive_loop(self):
        while self.running:
            await asyncio.sleep(1800)
            if not self.listen_key:
                continue
            try:
                api_key = GlobalConfig.get("binance_api_key")
                async with aiohttp.ClientSession() as session:
                    await session.put(
                        "https://fapi.binance.com/fapi/v1/listenKey",
                        headers={"X-MBX-APIKEY": api_key},
                        timeout=aiohttp.ClientTimeout(total=10),
                    )
                logging.debug("keep alive user stream à¸ªà¸³à¹€à¸£à¹‡à¸ˆ")
            except Exception as e:
                logging.error(f"keep alive user stream à¸¥à¹‰à¸¡à¹€à¸«à¸¥à¸§: {e}")

    async def _listen_user_stream(self, listen_key: str):
        url = f"{self.public_base}/ws/{listen_key}"
        try:
            async with websockets.connect(url, ping_interval=20, ping_timeout=20) as ws:
                logging.info("âœ… à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­ user stream à¸ªà¸³à¹€à¸£à¹‡à¸ˆ")
                while self.running:
                    raw = await ws.recv()
                    data = json.loads(raw)
                    await self._handle_user_data(data)
        except Exception as e:
            logging.error(f"user stream à¸¥à¹‰à¸¡à¹€à¸«à¸¥à¸§: {e}")

    # ---------------------- Public stream helpers ----------------------
    async def update_symbols(self, symbols: list[str]):
        new = {s.lower() + "@ticker" for s in symbols}
        self.subscribed_symbols = set(list(new)[:1024])
        logging.info(f"ðŸ“¡ à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¸£à¸²à¸¢à¸à¸²à¸£à¸ªà¸±à¸à¸¥à¸±à¸à¸©à¸“à¹Œ {len(self.subscribed_symbols)} streams")

    def _build_public_url(self, base: str) -> str:
        streams = "/".join(sorted(self.subscribed_symbols))
        return f"{base}/stream?streams={streams}"

    # ---------------------- Main start ----------------------
    @retry(wait=wait_exponential(multiplier=1, min=3, max=60), stop=stop_after_attempt(10))
    async def start(self):
        await self.fetch_all_usdt_pairs()
        if not self.all_usdt_pairs:
            logging.error("âŒ à¹„à¸¡à¹ˆà¸žà¸šà¸„à¸¹à¹ˆ USDT à¹ƒà¸”à¹†")
            return

        # ðŸŸ¢ à¹€à¸£à¸´à¹ˆà¸¡ task sync config à¸ªà¸”
        asyncio.create_task(self.auto_sync_config_loop())

        chunks = [self.all_usdt_pairs[i:i + 1024] for i in range(0, len(self.all_usdt_pairs), 1024)]
        for idx, chunk in enumerate(chunks):
            asyncio.create_task(self._start_chunk(chunk, idx))

    async def _start_chunk(self, symbols: list[str], group_idx: int = 0):
        await self.update_symbols(symbols)
        self.running = True
        self.start_time = time.time()

        asyncio.create_task(self.monitor_status_loop(10))
        asyncio.create_task(self.keep_alive_loop())

        if await self.create_listen_key():
            asyncio.create_task(self._listen_user_stream(self.listen_key))

        bases = [self.public_base, self.backup_base]
        idx = 0
        reconnects = 0

        while self.running:
            self.refresh_config()  # âœ… à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š config à¸—à¸¸à¸à¸„à¸£à¸±à¹‰à¸‡à¸à¹ˆà¸­à¸™ reconnect
            url = self._build_public_url(bases[idx])
            try:
                async with websockets.connect(url, ping_interval=20, ping_timeout=20) as ws:
                    logging.info(f"âœ… [{group_idx}] à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸ªà¸³à¹€à¸£à¹‡à¸ˆ {len(symbols)} à¸„à¸¹à¹ˆ")
                    while self.running:
                        try:
                            raw = await asyncio.wait_for(ws.recv(), timeout=self.ws_timeout)
                            data = json.loads(raw)
                            await self._handle_public_message(data)
                        except asyncio.TimeoutError:
                            pong_waiter = await ws.ping()
                            await pong_waiter
                            logging.debug(f"[{group_idx}] waiting data...")
            except Exception as e:
                reconnects += 1
                delay = min(5 * reconnects, self.reconnect_delay_max)
                logging.warning(f"[{group_idx}] reconnect {reconnects} : {e}")
                await asyncio.sleep(delay)
                idx = (idx + 1) % len(bases)

    # ---------------------- Handlers ----------------------
    async def _handle_public_message(self, payload: dict):
        try:
            msg = payload.get("data", payload)
            symbol = msg.get("s")
            if not symbol:
                return

            price = float(msg.get("c", 0))
            vol = float(msg.get("v", 0))
            ts = time.time()
            self.last_data_time = ts

            funding_rate = await self._safe_fetch_funding_rate(symbol)
            self.data[symbol] = {
                "timestamp": ts,
                "close": price,
                "volume": vol,
                "funding_rate": funding_rate,
                "depth": {},
            }
            self.cache[symbol] = self.data[symbol]

            if symbol not in self.price_buffer:
                self.price_buffer[symbol] = deque(maxlen=500)
            self.price_buffer[symbol].append({
                "timestamp": ts,
                "close": price,
                "volume": vol
            })

            self.db_conn.execute(
                "INSERT INTO ws_data (symbol, timestamp, close, volume, funding_rate, depth) VALUES (?, ?, ?, ?, ?, ?)",
                (symbol, ts, price, vol, funding_rate, 0),
            )
            await self._commit_safe()

            logging.info(f"ðŸ“ˆ {symbol} = {price:.2f} | Vol={vol:.2f} | FR={funding_rate:.6f}")
        except Exception as e:
            logging.error(f"à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸žà¸¥à¸²à¸”à¹ƒà¸™ _handle_public_message: {e}")

    async def _safe_fetch_funding_rate(self, symbol: str) -> float:
        try:
            url = f"https://fapi.binance.com/fapi/v1/premiumIndex?symbol={symbol}"
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=aiohttp.ClientTimeout(total=5)) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        return float(data.get("lastFundingRate", 0.0))
        except Exception:
            pass
        return 0.0

    async def _handle_user_data(self, data: dict):
        try:
            et = data.get("e")
            if et == "ACCOUNT_UPDATE":
                for b in data.get("a", {}).get("B", []):
                    if b.get("a") == "USDT":
                        self.balance_data["free"] = float(b.get("wb", 0.0))
                        self.balance_data["locked"] = float(b.get("cw", 0.0))
                        logging.info(f"ðŸ’° free={b.get('wb')} locked={b.get('cw')}")
            elif et == "ORDER_TRADE_UPDATE":
                o = data.get("o", {})
                logging.info(f"ðŸ“Š {o.get('s')} {o.get('S')} {o.get('X')} @ {o.get('p')}")
        except Exception as e:
            logging.error(f"à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸žà¸¥à¸²à¸”à¹ƒà¸™ _handle_user_data: {e}")

    # ---------------------- Monitor & Fallback ----------------------
    async def monitor_status_loop(self, interval: int = 10):
        while True:
            self.is_running()
            await asyncio.sleep(interval)

    def is_running(self) -> bool:
        uptime = timedelta(seconds=int(time.time() - self.start_time)) if self.start_time else timedelta(0)
        delay = time.time() - self.last_data_time
        if self.running:
            logging.info(f"âœ… à¸—à¸³à¸‡à¸²à¸™à¸›à¸à¸•à¸´ | Delay={delay:.1f}s | Uptime={uptime}")
        else:
            logging.warning("ðŸ›‘ à¸«à¸¢à¸¸à¸”à¸—à¸³à¸‡à¸²à¸™")
        return self.running

    async def use_fallback_data(self, symbols: list[str]):
        now = time.time()
        for s in symbols:
            self.data[s] = {"timestamp": now, "close": 0.0, "volume": 0.0, "funding_rate": 0.0, "depth": {}}
        logging.warning("âš ï¸ à¹ƒà¸Šà¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸³à¸¥à¸­à¸‡à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸£à¸°à¸šà¸šà¸—à¸³à¸‡à¸²à¸™à¸•à¹ˆà¸­")

    # ---------------------- Historical Buffer Interface ----------------------
    def get_recent_ohlcv(self, symbol: str, limit: int = 100) -> pd.DataFrame:
        data = list(self.price_buffer.get(symbol, []))[-limit:]
        if not data:
            return pd.DataFrame()
        df = pd.DataFrame(data)
        df["open"] = df["close"].shift(1).fillna(df["close"])
        df["high"] = df["close"] * 1.001
        df["low"] = df["close"] * 0.999
        return df[["open", "high", "low", "close", "volume"]]

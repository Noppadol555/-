# ===============================================
# main.py ‚Äî ‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏•‡∏≤‡∏™‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ó‡∏£‡∏î‡∏´‡∏•‡∏±‡∏Å (‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° WebSocket + APIManager)
# ===============================================

from config import GlobalConfig
import asyncio, logging, traceback
import numpy as np
import pandas as pd
import torch

# ==============================
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ó‡∏£‡∏î
# ==============================
async def main():
    logging.info("‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏î‡∏î‡πâ‡∏ß‡∏¢ CONFIG ‡∏à‡∏≤‡∏Å GlobalConfig")

    # ---------- ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏≠‡πá‡∏≠‡∏ö‡πÄ‡∏à‡πá‡∏Å‡∏ï‡πå‡∏´‡∏•‡∏±‡∏Å ----------
    api_manager = APIManager()
    ws_manager = WebSocketManager(exchange=api_manager.exchange, time_offset=api_manager.time_offset)
    trader = UnifiedQuantumTrader(GlobalConfig.get('input_dim'))
    risk_guardian = RiskGuardian()

    # üîπ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° WebSocketManager ‡πÅ‡∏•‡∏∞ Exchange ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö Environment
    env = MultiMarketEnv(ws_manager=ws_manager, exchange=api_manager.exchange)  # ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ã‡∏¥‡∏á‡∏Ñ‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå
    env.trader = trader

    trader.replay_buffer = ReplayBuffer()
    risk_guardian.env = env
    strategy_gen = StrategyGenerator(trader, env, risk_guardian)
    resource_manager = IntelligentResourceManager()
    kpi_optimizer = KPIOptimizer()
    risk_allocator = DynamicRiskAllocator()
    kpi_tracker = KPITracker()
    bug_fixer = AutomaticBugFixer()

    # ---------- ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏™‡∏ï‡∏£‡∏µ‡∏°‡∏£‡∏≤‡∏Ñ‡∏≤ / ‡πÄ‡∏´‡∏£‡∏µ‡∏¢‡∏ç ----------
    await ws_manager.fetch_all_usdt_pairs()
    await ws_manager.start()

    trader.current_symbols = ws_manager.all_usdt_pairs[: GlobalConfig.get('madrl_agent_count')]
    env.symbols = trader.current_symbols
    env.simulator.update_symbols(env.symbols)
    trader.madrl.update_symbols(env.symbols)

    # ---------- ‡∏á‡∏≤‡∏ô background ----------
    asyncio.create_task(resource_manager.monitor_resources())

    # ---------- ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á ----------
    for symbol in env.symbols:
        await env.load_historical_data(symbol)

    # ---------- ‡πÄ‡∏£‡∏¥‡πà‡∏° control loop ----------
    control_task = asyncio.create_task(control_loop())

    # ---------- ‡∏ï‡∏±‡πâ‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏£‡∏∞‡∏ö‡∏ö ----------
    try:
        GlobalConfig.set('system_running', True)
    except Exception:
        GlobalConfig.CONFIG['system_running'] = True

    step_count = 0
    trader.positions = {}

    # ==================================================
    # üîÅ ‡∏ß‡∏á‡∏£‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ó‡∏£‡∏î (Main Loop)
    # ==================================================
    while GlobalConfig.get('system_running'):
        try:
            # üî∏ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Checkpoint
            if step_count % GlobalConfig.get('checkpoint_interval') == 0:
                torch.save(trader.qnt.state_dict(), 'qnt_checkpoint.pth')
                logging.info(f"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å checkpoint ‡∏ó‡∏µ‡πà step {step_count}")

            # üî∏ ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏´‡∏£‡∏µ‡∏¢‡∏ç‡πÄ‡∏ó‡∏£‡∏î
            top_symbols = trader.select_top_coins(ws_manager.all_usdt_pairs, ws_manager.data, kpi_tracker)
            if set(top_symbols) != set(env.symbols):
                env.symbols = top_symbols
                env.simulator.update_symbols(top_symbols)
                trader.madrl.update_symbols(top_symbols)
                await ws_manager.update_symbols(top_symbols)

            # üî∏ ‡∏ó‡∏≥ 1 step ‡∏Ç‡∏≠‡∏á environment
            observation, rewards, done, info = await env.step()

            # üî∏ ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï KPI ‡πÅ‡∏•‡∏∞‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ó‡∏∏‡∏ô‡∏ï‡πà‡∏≠‡∏£‡∏≠‡∏ö
            total_profit = info.get('profit', 0.0)
            await kpi_tracker.update(total_profit)
            kpi_factor = kpi_optimizer.optimize(kpi_tracker.daily_profit)
            env.reinvest_cap = env.initial_balance * kpi_factor

            # üî∏ ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï risk
            await risk_guardian.update_dynamic_risk(ws_manager.data)
            risk_weights = await risk_allocator.allocate_risk(env.symbols, ws_manager.data, kpi_factor)

            # üî∏ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡∏£‡∏≤‡∏¢‡πÄ‡∏´‡∏£‡∏µ‡∏¢‡∏ç
            for i, symbol in enumerate(env.symbols):
                state = observation[i]

                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì volatility
                last_close = ws_manager.data.get(symbol, {}).get('close', None)
                series = [last_close] if last_close is not None else [0.0]
                volatility = float(np.std(series)) or 0.01

                # ‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå
                strategy = await strategy_gen.generate_strategy(state.reshape(1, -1), symbol, volatility)
                strategy['size'] *= risk_weights.get(symbol, GlobalConfig.get('risk_per_trade'))

                # ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏î
                profit = await strategy_gen.execute_strategy(strategy)

                # ========== üß† LOG ACTION ==========
                action_type = strategy.get('action', 'HOLD').upper()
                side = strategy.get('side', 'NEUTRAL').upper()
                position_size = strategy.get('size', 0)
                entry_price = strategy.get('entry_price', 0)

                if action_type == "BUY" or side == "LONG":
                    logging.info(f"üü¢ [{symbol}] ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ã‡∏∑‡πâ‡∏≠ (LONG) | Size={position_size:.4f} | Entry={entry_price}")
                elif action_type == "SELL" or side == "SHORT":
                    logging.info(f"üî¥ [{symbol}] ‡∏Ç‡∏≤‡∏¢/‡πÄ‡∏õ‡∏¥‡∏î SHORT | Size={position_size:.4f} | Entry={entry_price}")
                elif action_type == "HOLD":
                    logging.info(f"‚ö™ [{symbol}] ‡∏ñ‡∏∑‡∏≠‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÄ‡∏î‡∏¥‡∏° ‡∏£‡∏≠‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡πÉ‡∏´‡∏°‡πà...")
                else:
                    logging.info(f"üü° [{symbol}] Action={action_type}")

                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞
                trader.positions[symbol] = {
                    'side': side,
                    'size': position_size,
                    'entry_price': entry_price,
                    'timestamp': asyncio.get_event_loop().time(),
                }

                # multi timeframe data
                multi_tf_data = {
                    tf: env.multi_tf_data[tf].get(symbol, pd.DataFrame()).to_dict()
                    for tf in GlobalConfig.get('multi_tf_list', [])
                }

                # ‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå
                pred_discrete, pred_cont = trader.predict(state.reshape(1, -1))
                action_idx = int(np.argmax(pred_discrete[0]))
                cont_vec = pred_cont[0]

                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å replay
                trader.replay_buffer.add(
                    state,
                    action_idx,
                    cont_vec,
                    profit,
                    observation[i],
                    None,
                    None,
                    volatility,
                    multi_tf_data,
                )

                # ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏ö‡∏ö‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå
                await trader.evolve(state.reshape(1, -1), profit, volatility)

            # üî∏ ‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞
            if step_count % 1 == 0:
                active_positions = {s: trader.positions[s]['side'] for s in trader.positions if trader.positions[s]['size'] > 0}
                if active_positions:
                    logging.info(f"üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô: {active_positions}")
                else:
                    logging.info("üìä ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÄ‡∏õ‡∏¥‡∏î‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ (Flat)")

            # üî∏ ‡∏ù‡∏∂‡∏Å Reinforcement Learning
            if step_count % GlobalConfig.get('rl_train_interval') == 0 and getattr(trader.replay_buffer, "buffer", None):
                batch = trader.replay_buffer.sample(32)
                if batch:
                    states, discrete_actions, continuous_actions, rewards, next_states, _, _, atrs, multi_tf_data = batch
                    await trader.train(states, discrete_actions, continuous_actions, rewards, next_states)
                    await trader.adversarial_train(states)

            # üî∏ ‡∏õ‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ Bayesian Optimization
            if step_count % GlobalConfig.get('auto_ml_interval') == 0:
                trader.bayes_opt.maximize(init_points=2, n_iter=GlobalConfig.get('bayes_opt_steps'))
                trader.model_weights = trader.bayes_opt.max['params']
                logging.info(f"‡∏õ‡∏£‡∏±‡∏ö‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•: {trader.model_weights}")

            step_count += 1
            await asyncio.sleep(60)

        except Exception as e:
            if await bug_fixer.analyze_and_fix(e, trader, env):
                logging.info("‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ö‡∏±‡πä‡∏Å‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≠")
                continue
            logging.critical(f"‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡πâ‡∏≤‡∏¢‡πÅ‡∏£‡∏á: {e}")
            traceback.print_exc()
            await risk_guardian.emergency_stop()
            break

    # üîö ‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å control loop ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏´‡∏¢‡∏∏‡∏î‡∏£‡∏∞‡∏ö‡∏ö
    control_task.cancel()


if __name__ == "__main__":
    asyncio.run(main())

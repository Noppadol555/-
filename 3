# คลาสที่ 3: SSD

# ติดตั้งไลบรารีที่ต้องใช้สำหรับคลาสนี้ (รันคำสั่งเหล่านี้ใน terminal ก่อนใช้งาน)
# pip install torch

import torch
import torch.nn as nn
import numpy as np

class SSD(nn.Module):
    """
    โมเดล State Space Dynamics สำหรับทำนายสถานะถัดไป
    การใช้งาน: ใช้ในการทำนายสถานะถัดไปในระบบการเทรด โดยปรับ learning rate ตาม volatility
    Config ที่เกี่ยวข้อง: 'min_volatility_threshold' สำหรับปรับ adaptive_lr_factor ใน method train
    """
    def __init__(self, input_dim):
        """
        เริ่มต้นโมเดล SSD
        Args:
            input_dim (int): ขนาดของ input vector (จำนวน features)
        """
        super(SSD, self).__init__()
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, 128),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(128, 64),
            nn.ReLU()
        ).to(self.device)
        self.decoder = nn.Sequential(
            nn.Linear(64, 128),
            nn.ReLU(),
            nn.Linear(128, input_dim),
            nn.ReLU()
        ).to(self.device)
        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.0001, weight_decay=0.01)
        self.adaptive_lr_factor = 1.0

    def forward(self, x):
        """
        ประมวลผล input ผ่าน encoder และ decoder
        Args:
            x (torch.Tensor): Input tensor ขนาด (batch_size, input_dim)
        Returns:
            torch.Tensor: Output tensor ที่ทำนายสถานะถัดไป
        """
        x = x.to(self.device)
        latent = self.encoder(x)
        reconstructed = self.decoder(latent)
        return reconstructed

    def train(self, state_batch, next_state_batch, volatility=None):
        """
        ฝึกโมเดล SSD ด้วยข้อมูล state และ next_state
        Args:
            state_batch (np.ndarray): Batch ของสถานะปัจจุบัน
            next_state_batch (np.ndarray): Batch ของสถานะถัดไป
            volatility (float, optional): ความผันผวนสำหรับปรับ learning rate
        Returns:
            float: ค่า loss จากการฝึก
        """
        state_batch = torch.FloatTensor(state_batch).to(self.device)
        next_state_batch = torch.FloatTensor(next_state_batch).to(self.device)
        reconstructed = self.forward(state_batch)
        loss = nn.MSELoss()(reconstructed, next_state_batch)
        if volatility is not None:
            self.adaptive_lr_factor = min(1.0, max(0.1, volatility / GlobalConfig.get('min_volatility_threshold')))
            for param_group in self.optimizer.param_groups:
                param_group['lr'] = 0.0001 * self.adaptive_lr_factor
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        return loss.item()
